

Java 的参数是以值传递的形式传入方法中，而不是引用传递
> Java的参数传递，不管是原始类型还是引用类型，传递的都是副本(实参的拷贝)，一个是基本数据值的副本，一个是对象引用的副本。

OC 中对象的传递就是实实在在的对象指针，不是副本。

### String pool

**intern()**

当一个字符串调用 intern() 方法时,如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用.

采用 "bbb" 这种字面量的形式创建字符串，会自动地将字符串放入 String Pool 中

Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。
    
 
### javap -verbose 
 
 - 进行反编译 查看伪代码


### 数据转换
- Java 不能隐式执行向下转型，因为这会使得精度降低

    float f = 1.1 错误 1.1 是double  需要改成1.1f
    
    short s = 1  错误 int 比 short 精度高
    
    s++ 或者 s+=1 可以 隐式向下转换了
    

### switch

java7 后支持string 默认不支持long 因为初衷不是为过于复杂的情况设计，只是面向几个值的条件设计。

### 访问权限

什么都不写，表示包级别可见

protected 一般是用来对成员修饰，表示继承体系对子类可见，对类没有意义,只有子类实现了对应的方法，实例才能访问，否则不能

里氏替换：多态，IS-A 

字段建议不要用public ,提供set/get进行修饰， 注意和属性的区别。


### 抽象类和接口

java8 之后接口可以 有默认的实现方法。

接口中(默认也是)只能是public 修饰的字段和方法 ,字段还都只能是static 和 final修饰。


### 重写与重载
为了满足里式替换原则，重写有有以下两个限制：

* 子类方法的访问权限必须大于等于父类方法；
* 子类方法的返回类型必须是父类方法返回类型或为其子类型。

使用 @Override 注解，可以让编译器帮忙检查是否满足上面的两个限制条件。


### 等价与相等

1. equal()

    * 对于基本类型，== 判断两个值是否相等，基本类型没有 equals() 方法。

    * 对于引用类型，== 判断两个变量是否引用同一个对象，而 equals() 判断引用的对象是否等价。

    * 等价的两个对象散列值一定相同，但是散列值相同的两个对象不一定等价。

2. hashCode()

    * 31*x == (x<<5)-x
    
3. clone()

    * 实现 Cloneable 接口并且重写clone方法，才能调用clone() 方法。


### 静态
1. 静态方法必须有实现，也就是说它不能是抽象方法。



### Map 
ConcurrentHashMap HashTable 的替代，线程安全，高效 因为引入了分段锁。


### ArrayList

扩容是copy到一个新的数组,代价高，所以最好创建的时候就指定合适的大小。

-  Fail-Fast
   > modCount 用来记录 删除 或者 添加元素前后 集合中元素的个数，
    所以迭代中会比较迭代线程中的数组和主线程中数组这个值，所以不要在迭代的时候删除数据。
    
其内部的数组是transient 修饰的，即不支持序列化
但是实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。

> 所以它的序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。
  而ObjectOutputStream的writeObject() 方法在传入的对象存在 writeObject() 的时候会
  去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。

``` java
    ArrayList list =
    ArrayList list = new ArrayList();
    ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file));
    oos.writeObject(list);
```

***Vector 每次扩容请求其大小的 2 倍空间，而 ArrayList 是 1.5 倍。***

使用Collections.synchronizedList() 得到一个线程安全的 ArrayList。

或者使用 concurrent 并发包下的 CopyOnWriteArrayList 类。
``` java
List<String> list = new CopyOnWriteArrayList<>();
```

#### CopyOnWriteArrayList
- 读写分离
    
  写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。
  
  写操作需要加锁，防止并发写入时导致写入数据丢失。
  
  写操作结束之后需要把原始数组指向新的复制数组。
  
- CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。

#### HashMap
 看源码 哈哈 capacity 默认大小1<<4 即16  MUST be a power of two.
 
 1. 桶结构
    
    数组table + 桶下标(单向链表)。
    
    数组中每一个节点Node,Node是一个链表节点，next指向上一个被插入的节点，所以是头插法，即符合最近使用LRU 算法，方便取值。
    
    put() 如果原来存在则返回oldValue ,否则添加 返回null。
    
    
 
2. 取模(位运算的代价比求模运算小的多)
  
      x = 1<<4
      ``` 
       x   : 00010000
       x-1 : 00001111
        
       令一个数 y 与 x-1 做与运算，可以去除 y 位级表示的第 4 位以上数
       y       : 10110010
       x-1     : 00001111
       y&(x-1) : 00000010
      ```
      y & (x - 1) 等价于 y % x
  
3. 桶下标的获取

    确定桶下标的最后一步是将 key 的 hash 值对桶个数取模：hash%capacity，如果能保证 capacity 为 2 的 n 次方，那么就可以将这个操作转换为位运算。
      
    ```
       Node<K,V>[] tab; Node<K,V> p; int n, i;
       if ((tab = table) == null || (n = tab.length) == 0)
           n = (tab = resize()).length;
       //(n-1) & hash 就是获取桶下标
       if ((p = tab[i = (n - 1) & hash]) == null)
           tab[i] = newNode(hash, key, value, null);
       else {...}
    ```
  
4. 扩容

   设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此平均查找次数的复杂度为 O(N/M)。

   | 参数 | 含义 |
   | :------ | :------ |
   | capacity | table 的容量大小，默认为 16。需要注意的是 capacity 必须保证为 2 的 n 次方。|
   | size | table 的实际使用量。 |
   | threshold | size 的临界值，size 必须小于 threshold，如果大于等于，就必须进行扩容操作。 |
   | loadFactor | 装载因子，table 能够使用的比例，**threshold = capacity * loadFactor**。默认0.75 |
   

5. 链表转红黑树

    从 JDK 1.8 开始，一个桶存储的链表长度大于 8 时会将链表转换为红黑树


6. 与 HashTable 的比较
    - HashTable 使用 synchronized 来进行同步。
    - HashMap 可以插入键为 null 的 Entry。
    - HashMap 的迭代器是 fail-fast 迭代器。
    - HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。


#### ConcurrentHashMap

ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment）.

每个分段锁使用数组维护着几个桶（HashEntry）,即每个锁又维护个桶结构，多段hashMap，多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。

JDK1.7 使用分段锁，继承自重入锁 ReentrantLock

JDK1.8后改为CAS支持更高的并发度,JDK 1.8 的实现也在链表过长时会转换为红黑树

数组 -> 元素是分段锁 -> 每一个分段锁维护一个数组 -> 每一个数组存放多个Entry -> entry链表

#### LinkedHashMap

accessOrder 决定了顺序，默认为 false，此时维护的是插入顺序

继承它 实现一个 LRU 缓存

```java
class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private static final int MAX_ENTRIES = 3;//最大缓存空间

    //核心就是这里，需要重写这个方法，在什么条件下删除首部元素
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return size() > MAX_ENTRIES;
    }
    
    LRUCache() {
        super(MAX_ENTRIES, 0.75f, true);
    }
}
```



#### WeakHashMap

一般被用来做缓存结构，WeakHashMap 的 Entry 继承自 WeakReference。

Tomcat中的ConcurrentCache 采取的是分代缓存：

* 经常使用的对象放入 eden 中，eden 使用 ConcurrentHashMap 实现，不用担心会被回收（伊甸园）；
* 不常用的对象放入 longterm，longterm 使用 WeakHashMap 实现，这些老对象会被垃圾收集器回收。
* 当调用 get() 方法时，会先从 eden 区获取，如果没有找到的话再到 longterm 获取，当从 longterm 获取到就把对象放入 eden 中，从而保证经常被访问的节点不容易被回收。
* 当调用 put() 方法时，如果 eden 的大小超过了 size，那么就将 eden 中的所有对象都放入 longterm 中，利用虚拟机回收掉一部分不经常使用的对象。